from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import re
import csv
import io
import os
from typing import List, Dict, Any

# Ã‡oklu model yÃ¼kle
MODELS = {
    "savasy": {
        "name": "savasy/bert-base-turkish-sentiment-cased",
        "description": "TÃ¼rkÃ§e iÃ§in Ã¶zel eÄŸitilmiÅŸ sentiment modeli"
    },
    "dbmdz": {
        "name": "dbmdz/bert-base-turkish-cased", 
        "description": "Genel TÃ¼rkÃ§e BERT modeli"
    }
}

# Model pipeline'larÄ±
pipelines = {}
for model_id, model_info in MODELS.items():
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_info["name"])
        model = AutoModelForSequenceClassification.from_pretrained(model_info["name"])
        pipelines[model_id] = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
        print(f"âœ… {model_id} modeli yÃ¼klendi: {model_info['name']}")
    except Exception as e:
        print(f"âŒ {model_id} modeli yÃ¼klenemedi: {e}")

# API baÅŸlat
app = FastAPI(title="TÃ¼rkÃ§e Duygu Analizi API - Ã‡oklu Model", version="2.0.0")

# Static dosyalarÄ± serve et
app.mount("/static", StaticFiles(directory="static"), name="static")

class Comment(BaseModel):
    text: str

class Comments(BaseModel):
    texts: List[str]

# Etiket eÅŸleme - farklÄ± modeller iÃ§in
MAPPINGS = {
    "savasy": {"positive": "Olumlu", "negative": "Olumsuz", "neutral": "NÃ¶tr"},
    "dbmdz": {"LABEL_0": "Olumsuz", "LABEL_1": "Olumlu", "LABEL_2": "NÃ¶tr"}  # Genel BERT iÃ§in
}

def is_neutral_comment(text: str) -> bool:
    """NÃ¶tr yorumlarÄ± tespit et - Ã¶zellikle iÅŸ yeri talepleri ve Ã¶nerileri iÃ§in"""
    text_lower = text.lower()
    
    # NÃ¶tr gÃ¶stergeler (talep, Ã¶neri, rica) - daha geniÅŸ liste
    neutral_indicators = [
        'talep ediyoruz', 'istiyoruz', 'rica ediyoruz', 'aÃ§Ä±lmasÄ±nÄ± istiyoruz',
        'bulunmak istiyoruz', 'teÅŸekkÃ¼r ederiz', 'hayÄ±rlÄ± akÅŸamlar', 'hayÄ±rlÄ± gÃ¼nler',
        'personel', 'lojman', 'mescit', 'kahve makinesi', 'dinlenme alanÄ±',
        'yÃ¶netim kurulu', 'sizden ricamÄ±z', 'aÃ§Ä±lmasÄ±nÄ± talep ediyoruz',
        'eklenmesini istiyoruz', 'kurulmasÄ±nÄ± istiyoruz', 'yapÄ±lmasÄ±nÄ± istiyoruz',
        'dÃ¼zenlenmesini istiyoruz', 'iyileÅŸtirilmesini istiyoruz',
        'olmasÄ±nÄ± istiyoruz', 'olmasÄ±nÄ± talep ediyoruz', 'olmasÄ±nÄ± rica ediyoruz',
        'artÄ±rÄ±lmasÄ±nÄ± istiyoruz', 'azaltÄ±lmasÄ±nÄ± istiyoruz', 'deÄŸiÅŸtirilmesini istiyoruz',
        'yemekhane', 'internet', 'Ã§alÄ±ÅŸma saati', 'Ã§alÄ±ÅŸma ortamÄ±', 'sosyal alan',
        'spor salonu', 'otopark', 'ulaÅŸÄ±m', 'servis', 'yemek', 'Ã§ay', 'kahve',
        'temizlik', 'gÃ¼venlik', 'bakÄ±m', 'onarÄ±m', 'yenileme', 'modernizasyon'
    ]
    
    # Åikayet gÃ¶stergeleri (gerÃ§ekten olumsuz olanlar)
    complaint_indicators = [
        'kÃ¶tÃ¼', 'berbat', 'rezalet', 'Ã§ok kÃ¶tÃ¼', 'hiÃ§ beÄŸenmedim', 'beÄŸenmedim',
        'ÅŸikayet', 'memnun deÄŸilim', 'kÄ±zgÄ±nÄ±m', 'sinirliyim', 'Ã¼zgÃ¼nÃ¼m',
        'yetersiz', 'kÃ¶tÃ¼ kalite', 'dÃ¼ÅŸÃ¼k kalite', 'sorunlu', 'problemli',
        'Ã§alÄ±ÅŸmÄ±yor', 'bozuk', 'arÄ±zalÄ±', 'hatalÄ±', 'yanlÄ±ÅŸ', 'kÄ±rÄ±k',
        'eski', 'kirli', 'pis', 'kÃ¶tÃ¼ kokuyor', 'gÃ¼rÃ¼ltÃ¼lÃ¼', 'sÄ±cak', 'soÄŸuk'
    ]
    
    # Pozitif gÃ¶stergeler
    positive_indicators = [
        'Ã§ok iyi', 'harika', 'mÃ¼kemmel', 'sÃ¼per', 'gÃ¼zel', 'beÄŸendim',
        'memnun', 'teÅŸekkÃ¼r', 'baÅŸarÄ±lÄ±', 'kaliteli', 'profesyonel',
        'sorunsuz', 'tam istediÄŸimiz gibi', 'Ã§ok gÃ¼zel', 'Ã§ok baÅŸarÄ±lÄ±'
    ]
    
    neutral_count = sum(1 for indicator in neutral_indicators if indicator in text_lower)
    complaint_count = sum(1 for indicator in complaint_indicators if indicator in text_lower)
    positive_count = sum(1 for indicator in positive_indicators if indicator in text_lower)
    
    # NÃ¶tr yorum kriterleri - daha esnek:
    # 1. NÃ¶tr gÃ¶stergeler yeterli (2+)
    # 2. Åikayet gÃ¶stergeleri az (2'den az)
    # 3. Pozitif gÃ¶stergeler varsa da nÃ¶tr olabilir (talep + pozitif = nÃ¶tr)
    if neutral_count >= 2 and complaint_count <= 1:
        return True
    
    # Ã–zel durum: "herÅŸey Ã§ok iyi sorunsuz fakat" gibi yapÄ±lar
    if 'fakat' in text_lower or 'ama' in text_lower or 'ancak' in text_lower:
        if neutral_count >= 1:
            return True
    
    # Ã–zel durum: "istiyoruz", "talep ediyoruz" gibi direkt talepler
    if any(word in text_lower for word in ['istiyoruz', 'talep ediyoruz', 'rica ediyoruz']):
        if complaint_count == 0:
            return True
    
    # Ã–zel durum: Personel, lojman, yemekhane gibi iÅŸ yeri konularÄ±
    workplace_topics = ['personel', 'lojman', 'yemekhane', 'mescit', 'dinlenme', 'Ã§alÄ±ÅŸma']
    if any(topic in text_lower for topic in workplace_topics):
        if neutral_count >= 1 and complaint_count <= 1:
            return True
    
    return False

def clean_text(text: str) -> str:
    """Metni normalize et ve temizle"""
    text = text.lower()
    # TÃ¼rkÃ§e karakterleri koru, gereksiz iÅŸaretleri temizle
    text = re.sub(r'[^\w\sÃ§ÄŸÄ±Ã¶ÅŸÃ¼]', '', text)
    # Tekrar eden harfleri azalt (Ã¶r: aaa -> aa)
    text = re.sub(r'(.)\1{2,}', r'\1\1', text)
    # Fazla boÅŸluklarÄ± temizle
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def analyze_with_model(text: str, model_id: str) -> Dict[str, Any]:
    """Belirli bir model ile analiz"""
    try:
        pipeline = pipelines.get(model_id)
        if not pipeline:
            return {"error": f"Model {model_id} bulunamadÄ±"}
        
        result = pipeline(text)[0]
        label = str(result['label'])
        confidence = float(result['score'])
        
        # Model'e gÃ¶re etiket eÅŸleme
        mapping = MAPPINGS.get(model_id, {})
        sentiment = mapping.get(label, label)
        
        return {
            "model_id": model_id,
            "sentiment": sentiment,
            "confidence": confidence,
            "raw_label": label
        }
    except Exception as e:
        return {"error": str(e)}

def combine_model_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Ã‡oklu model sonuÃ§larÄ±nÄ± birleÅŸtir"""
    valid_results = [r for r in results if "error" not in r]
    
    if not valid_results:
        return {"error": "HiÃ§bir model Ã§alÄ±ÅŸmadÄ±"}
    
    if len(valid_results) == 1:
        return valid_results[0]
    
    # Ã‡oklu model sonuÃ§larÄ±nÄ± analiz et
    sentiments = [r["sentiment"] for r in valid_results]
    confidences = [r["confidence"] for r in valid_results]
    
    # En yÃ¼ksek gÃ¼ven skoruna sahip sonucu al
    best_result = max(valid_results, key=lambda x: x["confidence"])
    
    # SonuÃ§lar tutarlÄ± mÄ± kontrol et
    unique_sentiments = set(sentiments)
    is_consistent = len(unique_sentiments) == 1
    
    return {
        "final_sentiment": best_result["sentiment"],
        "final_confidence": best_result["confidence"],
        "model_used": best_result["model_id"],
        "consistency": is_consistent,
        "all_results": valid_results,
        "method": "multi_model"
    }

def analyze_comment(comment: str) -> Dict[str, Any]:
    """Tek yorum analizi - geliÅŸmiÅŸ hibrit yaklaÅŸÄ±m"""
    if not comment or len(comment.strip()) < 2:
        raise HTTPException(status_code=400, detail="Yorum Ã§ok kÄ±sa veya boÅŸ")
    
    # 1. Ã–nce kural tabanlÄ± kontrol
    if is_neutral_comment(comment):
        return {
            "yorum": comment,
            "analiz": "NÃ¶tr",
            "gÃ¼ven": 0.95,
            "yÃ¶ntem": "kural_tabanlÄ±",
            "aÃ§Ä±klama": "Talep, Ã¶neri veya rica iÃ§eren yorum",
            "model_sonuÃ§larÄ±": None
        }
    
    cleaned = clean_text(comment)
    if len(cleaned.split()) < 2:
        return {
            "yorum": comment,
            "analiz": "GeÃ§ersiz / Yetersiz Yorum",
            "gÃ¼ven": 0.0,
            "yÃ¶ntem": "kural_tabanlÄ±",
            "model_sonuÃ§larÄ±": None
        }
    
    try:
        # 2. Ã‡oklu model analizi
        model_results = []
        for model_id in pipelines.keys():
            result = analyze_with_model(cleaned, model_id)
            if "error" not in result:
                model_results.append(result)
        
        # 3. Model sonuÃ§larÄ±nÄ± birleÅŸtir
        combined_result = combine_model_results(model_results)
        
        if "error" in combined_result:
            raise Exception(combined_result["error"])
        
        final_sentiment = combined_result["final_sentiment"]
        final_confidence = combined_result["final_confidence"]
        
        # 4. Model sonucunu kontrol et - eÄŸer Ã§ok yÃ¼ksek gÃ¼venle yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±yorsa
        if final_confidence > 0.9 and final_sentiment == "Olumsuz":
            if is_neutral_comment(comment):
                return {
                    "yorum": comment,
                    "analiz": "NÃ¶tr",
                    "gÃ¼ven": 0.90,
                    "yÃ¶ntem": "hibrit_dÃ¼zeltme",
                    "aÃ§Ä±klama": "Model yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rdÄ±, kural tabanlÄ± dÃ¼zeltme uygulandÄ±",
                    "model_sonuÃ§larÄ±": combined_result
                }
        
        return {
            "yorum": comment,
            "analiz": final_sentiment,
            "gÃ¼ven": round(final_confidence, 3),
            "yÃ¶ntem": combined_result["method"],
            "model_sonuÃ§larÄ±": combined_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analiz hatasÄ±: {str(e)}")

def analyze_comments(comments: List[str]) -> List[Dict[str, Any]]:
    """Toplu yorum analizi"""
    if not comments:
        return []
    
    # BoÅŸ yorumlarÄ± filtrele
    valid_comments = [c.strip() for c in comments if c.strip()]
    if not valid_comments:
        return []
    
    try:
        outputs = []
        for comment in valid_comments:
            outputs.append(analyze_comment(comment))
        return outputs
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Toplu analiz hatasÄ±: {str(e)}")

def parse_csv_file(file_content: bytes) -> List[str]:
    """CSV dosyasÄ±ndan yorumlarÄ± oku"""
    try:
        content = file_content.decode('utf-8')
        csv_reader = csv.reader(io.StringIO(content))
        comments = []
        for row in csv_reader:
            if row and row[0].strip():
                comments.append(row[0].strip())
        return comments
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"CSV okuma hatasÄ±: {str(e)}")

def parse_txt_file(file_content: bytes) -> List[str]:
    """TXT dosyasÄ±ndan yorumlarÄ± oku"""
    try:
        content = file_content.decode('utf-8')
        lines = [line.strip() for line in content.splitlines() if line.strip()]
        return lines
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"TXT okuma hatasÄ±: {str(e)}")

# VeritabanÄ± iÃ§in basit JSON dosya sistemi
import json
import os
from datetime import datetime

# VeritabanÄ± dosyasÄ±
DB_FILE = "sentiment_database.json"

def load_database():
    """VeritabanÄ±nÄ± yÃ¼kle"""
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {
        "comments": [],
        "statistics": {
            "total": 0,
            "positive": 0,
            "negative": 0,
            "neutral": 0,
            "invalid": 0
        },
        "last_updated": datetime.now().isoformat()
    }

def save_database(db):
    """VeritabanÄ±nÄ± kaydet"""
    db["last_updated"] = datetime.now().isoformat()
    with open(DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(db, f, ensure_ascii=False, indent=2)

def add_comment_to_database(comment_data):
    """Yorumu veritabanÄ±na ekle"""
    db = load_database()
    
    # Yorum ID'si oluÅŸtur
    comment_id = len(db["comments"]) + 1
    
    # Yorum verisi
    comment_entry = {
        "id": comment_id,
        "text": comment_data["yorum"],
        "sentiment": comment_data["analiz"],
        "confidence": comment_data["gÃ¼ven"],
        "method": comment_data.get("yÃ¶ntem", "bilinmiyor"),
        "timestamp": datetime.now().isoformat(),
        "model_results": comment_data.get("model_sonuÃ§larÄ±", None)
    }
    
    db["comments"].append(comment_entry)
    
    # Ä°statistikleri gÃ¼ncelle
    db["statistics"]["total"] += 1
    sentiment = comment_data["analiz"]
    if sentiment == "Olumlu":
        db["statistics"]["positive"] += 1
    elif sentiment == "Olumsuz":
        db["statistics"]["negative"] += 1
    elif sentiment == "NÃ¶tr":
        db["statistics"]["neutral"] += 1
    else:
        db["statistics"]["invalid"] += 1
    
    save_database(db)
    return comment_id

@app.get("/", response_class=HTMLResponse)
async def read_root():
    """Ana sayfa - HTML arayÃ¼zÃ¼nÃ¼ serve et"""
    try:
        html_path = os.path.join("static", "index.html")
        if os.path.exists(html_path):
            with open(html_path, "r", encoding="utf-8") as f:
                return HTMLResponse(content=f.read())
        else:
            # HTML dosyasÄ± bulunamadÄ±ysa basit bir sayfa dÃ¶ndÃ¼r
            return HTMLResponse(content="""
            <!DOCTYPE html>
            <html lang="tr">
            <head>
                <meta charset="UTF-8">
                <title>TÃ¼rkÃ§e Duygu Analizi - Ã‡oklu Model</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 40px; }
                    .container { max-width: 800px; margin: 0 auto; }
                    .endpoint { background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 5px; }
                    .method { font-weight: bold; color: #007bff; }
                    .model-info { background: #e8f4fd; padding: 15px; margin: 10px 0; border-radius: 5px; }
                </style>
            </head>
            <body>
                <div class="container">
                    <h1>ğŸ­ TÃ¼rkÃ§e Duygu Analizi API - Ã‡oklu Model</h1>
                    <p>API Ã§alÄ±ÅŸÄ±yor! KullanÄ±labilir endpoint'ler:</p>
                    
                    <div class="model-info">
                        <h3>ğŸ¤– YÃ¼klÃ¼ Modeller</h3>
                        <ul>
                            <li><strong>savasy</strong>: TÃ¼rkÃ§e sentiment iÃ§in Ã¶zel eÄŸitilmiÅŸ</li>
                            <li><strong>dbmdz</strong>: Genel TÃ¼rkÃ§e BERT modeli</li>
                        </ul>
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">GET</span> <code>/</code> - Bu sayfa
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">POST</span> <code>/analyze</code> - Tek yorum analizi
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">POST</span> <code>/analyze-batch</code> - Toplu yorum analizi (JSON)
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">POST</span> <code>/upload</code> - Dosya yÃ¼kleme ve analiz
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">GET</span> <code>/health</code> - SaÄŸlÄ±k kontrolÃ¼
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">GET</span> <code>/docs</code> - Swagger dokÃ¼mantasyonu
                    </div>
                    
                    <h3>ğŸ“ Ã–rnek KullanÄ±m</h3>
                    <p><strong>Tek yorum analizi:</strong></p>
                    <pre>curl -X POST "http://localhost:8000/analyze" \
     -H "Content-Type: application/json" \
     -d '{"text": "Bu Ã¼rÃ¼n harika!"}'</pre>
                    
                    <p><strong>Dosya yÃ¼kleme:</strong></p>
                    <pre>curl -X POST "http://localhost:8000/upload" \
     -F "file=@ornek_yorumlar.txt"</pre>
                </div>
            </body>
            </html>
            """)
    except Exception as e:
        return HTMLResponse(content=f"""
        <html>
            <head><title>Hata</title></head>
            <body><h1>Hata oluÅŸtu: {str(e)}</h1></body>
        </html>
        """)

@app.post("/analyze")
async def analyze_single(comment: Comment):
    """Tek yorum analizi - geliÅŸmiÅŸ hibrit yaklaÅŸÄ±m"""
    if not comment or len(comment.strip()) < 2:
        raise HTTPException(status_code=400, detail="Yorum Ã§ok kÄ±sa veya boÅŸ")
    
    # 1. Ã–nce kural tabanlÄ± kontrol
    if is_neutral_comment(comment.text):
        result = {
            "yorum": comment.text,
            "analiz": "NÃ¶tr",
            "gÃ¼ven": 0.95,
            "yÃ¶ntem": "kural_tabanlÄ±",
            "aÃ§Ä±klama": "Talep, Ã¶neri veya rica iÃ§eren yorum",
            "model_sonuÃ§larÄ±": None
        }
    else:
        cleaned = clean_text(comment.text)
        if len(cleaned.split()) < 2:
            result = {
                "yorum": comment.text,
                "analiz": "GeÃ§ersiz / Yetersiz Yorum",
                "gÃ¼ven": 0.0,
                "yÃ¶ntem": "kural_tabanlÄ±",
                "model_sonuÃ§larÄ±": None
            }
        else:
            try:
                # 2. Ã‡oklu model analizi
                model_results = []
                for model_id in pipelines.keys():
                    result_model = analyze_with_model(cleaned, model_id)
                    if "error" not in result_model:
                        model_results.append(result_model)
                
                # 3. Model sonuÃ§larÄ±nÄ± birleÅŸtir
                combined_result = combine_model_results(model_results)
                
                if "error" in combined_result:
                    raise Exception(combined_result["error"])
                
                final_sentiment = combined_result["final_sentiment"]
                final_confidence = combined_result["final_confidence"]
                
                # 4. Model sonucunu kontrol et - eÄŸer Ã§ok yÃ¼ksek gÃ¼venle yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±yorsa
                if final_confidence > 0.9 and final_sentiment == "Olumsuz":
                    if is_neutral_comment(comment.text):
                        result = {
                            "yorum": comment.text,
                            "analiz": "NÃ¶tr",
                            "gÃ¼ven": 0.90,
                            "yÃ¶ntem": "hibrit_dÃ¼zeltme",
                            "aÃ§Ä±klama": "Model yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rdÄ±, kural tabanlÄ± dÃ¼zeltme uygulandÄ±",
                            "model_sonuÃ§larÄ±": combined_result
                        }
                    else:
                        result = {
                            "yorum": comment.text,
                            "analiz": final_sentiment,
                            "gÃ¼ven": round(final_confidence, 3),
                            "yÃ¶ntem": combined_result["method"],
                            "model_sonuÃ§larÄ±": combined_result
                        }
                else:
                    result = {
                        "yorum": comment.text,
                        "analiz": final_sentiment,
                        "gÃ¼ven": round(final_confidence, 3),
                        "yÃ¶ntem": combined_result["method"],
                        "model_sonuÃ§larÄ±": combined_result
                    }
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Analiz hatasÄ±: {str(e)}")
    
    # Yorumu veritabanÄ±na ekle
    try:
        comment_id = add_comment_to_database(result)
        result["comment_id"] = comment_id
    except Exception as e:
        print(f"VeritabanÄ± hatasÄ±: {e}")
        result["comment_id"] = None
    
    return result

@app.post("/analyze-batch")
async def analyze_batch(payload: Comments):
    """JSON ile toplu yorum analizi"""
    return analyze_comments(payload.texts)

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """Dosya yÃ¼kleme ve analiz"""
    if not file.filename:
        raise HTTPException(status_code=400, detail="Dosya adÄ± bulunamadÄ±")
    
    # Dosya boyutu kontrolÃ¼ (5MB)
    if file.size and file.size > 5 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="Dosya Ã§ok bÃ¼yÃ¼k (max 5MB)")
    
    try:
        content = await file.read()
        
        if file.filename.lower().endswith('.csv'):
            comments = parse_csv_file(content)
        elif file.filename.lower().endswith('.txt'):
            comments = parse_txt_file(content)
        else:
            raise HTTPException(status_code=400, detail="Sadece .csv ve .txt dosyalarÄ± desteklenir")
        
        if not comments:
            raise HTTPException(status_code=400, detail="Dosyada geÃ§erli yorum bulunamadÄ±")
        
        results = analyze_comments(comments)
        return {
            "dosya_adi": file.filename,
            "yorum_sayisi": len(comments),
            "sonuclar": results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Dosya iÅŸleme hatasÄ±: {str(e)}")

@app.get("/health")
async def health_check():
    """SaÄŸlÄ±k kontrolÃ¼"""
    return {
        "status": "healthy", 
        "models": {model_id: {"name": info["name"], "status": "loaded"} for model_id, info in MODELS.items()},
        "pipelines": list(pipelines.keys())
    }

@app.get("/statistics")
async def get_statistics():
    """GÃ¼ncel istatistikleri getir"""
    try:
        db = load_database()
        return {
            "status": "success",
            "data": db["statistics"],
            "last_updated": db["last_updated"],
            "total_comments": len(db["comments"])
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ä°statistik hatasÄ±: {str(e)}")

@app.get("/comments")
async def get_comments(limit: int = 50, offset: int = 0):
    """YorumlarÄ± getir"""
    try:
        db = load_database()
        comments = db["comments"][offset:offset+limit]
        return {
            "status": "success",
            "data": comments,
            "total": len(db["comments"]),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Yorum getirme hatasÄ±: {str(e)}")

@app.get("/comments/{comment_id}")
async def get_comment(comment_id: int):
    """Belirli bir yorumu getir"""
    try:
        db = load_database()
        if comment_id <= 0 or comment_id > len(db["comments"]):
            raise HTTPException(status_code=404, detail="Yorum bulunamadÄ±")
        
        comment = db["comments"][comment_id - 1]
        return {
            "status": "success",
            "data": comment
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Yorum getirme hatasÄ±: {str(e)}")

@app.delete("/comments/{comment_id}")
async def delete_comment(comment_id: int):
    """Yorumu sil"""
    try:
        db = load_database()
        if comment_id <= 0 or comment_id > len(db["comments"]):
            raise HTTPException(status_code=404, detail="Yorum bulunamadÄ±")
        
        # Yorumu sil
        deleted_comment = db["comments"].pop(comment_id - 1)
        
        # Ä°statistikleri gÃ¼ncelle
        sentiment = deleted_comment["sentiment"]
        db["statistics"]["total"] -= 1
        if sentiment == "Olumlu":
            db["statistics"]["positive"] -= 1
        elif sentiment == "Olumsuz":
            db["statistics"]["negative"] -= 1
        elif sentiment == "NÃ¶tr":
            db["statistics"]["neutral"] -= 1
        else:
            db["statistics"]["invalid"] -= 1
        
        # ID'leri yeniden dÃ¼zenle
        for i, comment in enumerate(db["comments"]):
            comment["id"] = i + 1
        
        save_database(db)
        
        return {
            "status": "success",
            "message": "Yorum baÅŸarÄ±yla silindi",
            "deleted_comment": deleted_comment
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Yorum silme hatasÄ±: {str(e)}")

@app.post("/analyze-bulk")
async def analyze_bulk_comments(comments: List[str]):
    """Toplu yorum analizi"""
    if not comments or len(comments) == 0:
        raise HTTPException(status_code=400, detail="Yorum listesi boÅŸ")
    
    if len(comments) > 100:
        raise HTTPException(status_code=400, detail="Maksimum 100 yorum analiz edilebilir")
    
    results = []
    start_time = time.time()
    
    for comment_text in comments:
        try:
            # Her yorumu analiz et
            comment_obj = Comment(text=comment_text)
            result = await analyze_single(comment_obj)
            results.append(result)
        except Exception as e:
            results.append({
                "yorum": comment_text,
                "analiz": "Hata",
                "gÃ¼ven": 0.0,
                "yÃ¶ntem": "hata",
                "aÃ§Ä±klama": str(e),
                "comment_id": None
            })
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    return {
        "status": "success",
        "message": f"{len(comments)} yorum analiz edildi",
        "results": results,
        "processing_time": round(processing_time, 2),
        "average_time_per_comment": round(processing_time / len(comments), 3)
    }

@app.get("/export")
async def export_data(format: str = "json"):
    """Veriyi dÄ±ÅŸa aktar"""
    try:
        db = load_database()
        
        if format.lower() == "csv":
            import csv
            from io import StringIO
            
            output = StringIO()
            writer = csv.writer(output)
            
            # CSV baÅŸlÄ±klarÄ±
            writer.writerow(["ID", "Yorum", "Sentiment", "GÃ¼ven", "YÃ¶ntem", "Tarih"])
            
            # Verileri yaz
            for comment in db["comments"]:
                writer.writerow([
                    comment["id"],
                    comment["text"],
                    comment["sentiment"],
                    comment["confidence"],
                    comment["method"],
                    comment["timestamp"]
                ])
            
            output.seek(0)
            return Response(
                content=output.getvalue(),
                media_type="text/csv",
                headers={"Content-Disposition": f"attachment; filename=sentiment_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"}
            )
        
        else:  # JSON format
            return {
                "status": "success",
                "data": db,
                "export_time": datetime.now().isoformat()
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DÄ±ÅŸa aktarma hatasÄ±: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
