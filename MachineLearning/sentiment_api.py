from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import re
import csv
import io
import os
from typing import List, Dict, Any

# √áoklu model y√ºkle
MODELS = {
    "savasy": {
        "name": "savasy/bert-base-turkish-sentiment-cased",
        "description": "T√ºrk√ße i√ßin √∂zel eƒüitilmi≈ü sentiment modeli"
    },
    "dbmdz": {
        "name": "dbmdz/bert-base-turkish-cased", 
        "description": "Genel T√ºrk√ße BERT modeli"
    }
}

# Model pipeline'larƒ±
pipelines = {}
for model_id, model_info in MODELS.items():
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_info["name"])
        model = AutoModelForSequenceClassification.from_pretrained(model_info["name"])
        pipelines[model_id] = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
        print(f"‚úÖ {model_id} modeli y√ºklendi: {model_info['name']}")
    except Exception as e:
        print(f"‚ùå {model_id} modeli y√ºklenemedi: {e}")

# API ba≈ülat
app = FastAPI(title="T√ºrk√ße Duygu Analizi API - √áoklu Model", version="2.0.0")

# Static dosyalarƒ± serve et
app.mount("/static", StaticFiles(directory="static"), name="static")

class Comment(BaseModel):
    text: str

class Comments(BaseModel):
    texts: List[str]

# Etiket e≈üleme - farklƒ± modeller i√ßin
MAPPINGS = {
    "savasy": {"positive": "Olumlu", "negative": "Olumsuz", "neutral": "N√∂tr"},
    "dbmdz": {"LABEL_0": "Olumsuz", "LABEL_1": "Olumlu", "LABEL_2": "N√∂tr"}  # Genel BERT i√ßin
}

def is_neutral_comment(text: str) -> bool:
    """N√∂tr yorumlarƒ± tespit et - √∂zellikle i≈ü yeri talepleri ve √∂nerileri i√ßin"""
    text_lower = text.lower()
    
    # N√∂tr g√∂stergeler (talep, √∂neri, rica) - daha geni≈ü liste
    neutral_indicators = [
        'talep ediyoruz', 'istiyoruz', 'rica ediyoruz', 'a√ßƒ±lmasƒ±nƒ± istiyoruz',
        'bulunmak istiyoruz', 'te≈üekk√ºr ederiz', 'hayƒ±rlƒ± ak≈üamlar', 'hayƒ±rlƒ± g√ºnler',
        'personel', 'lojman', 'mescit', 'kahve makinesi', 'dinlenme alanƒ±',
        'y√∂netim kurulu', 'sizden ricamƒ±z', 'a√ßƒ±lmasƒ±nƒ± talep ediyoruz',
        'eklenmesini istiyoruz', 'kurulmasƒ±nƒ± istiyoruz', 'yapƒ±lmasƒ±nƒ± istiyoruz',
        'd√ºzenlenmesini istiyoruz', 'iyile≈ütirilmesini istiyoruz',
        'olmasƒ±nƒ± istiyoruz', 'olmasƒ±nƒ± talep ediyoruz', 'olmasƒ±nƒ± rica ediyoruz',
        'artƒ±rƒ±lmasƒ±nƒ± istiyoruz', 'azaltƒ±lmasƒ±nƒ± istiyoruz', 'deƒüi≈ütirilmesini istiyoruz',
        'yemekhane', 'internet', '√ßalƒ±≈üma saati', '√ßalƒ±≈üma ortamƒ±', 'sosyal alan',
        'spor salonu', 'otopark', 'ula≈üƒ±m', 'servis', 'yemek', '√ßay', 'kahve',
        'temizlik', 'g√ºvenlik', 'bakƒ±m', 'onarƒ±m', 'yenileme', 'modernizasyon'
    ]
    
    # ≈ûikayet g√∂stergeleri (ger√ßekten olumsuz olanlar)
    complaint_indicators = [
        'k√∂t√º', 'berbat', 'rezalet', '√ßok k√∂t√º', 'hi√ß beƒüenmedim', 'beƒüenmedim',
        '≈üikayet', 'memnun deƒüilim', 'kƒ±zgƒ±nƒ±m', 'sinirliyim', '√ºzg√ºn√ºm',
        'yetersiz', 'k√∂t√º kalite', 'd√º≈ü√ºk kalite', 'sorunlu', 'problemli',
        '√ßalƒ±≈ümƒ±yor', 'bozuk', 'arƒ±zalƒ±', 'hatalƒ±', 'yanlƒ±≈ü', 'kƒ±rƒ±k',
        'eski', 'kirli', 'pis', 'k√∂t√º kokuyor', 'g√ºr√ºlt√ºl√º', 'sƒ±cak', 'soƒüuk'
    ]
    
    # Pozitif g√∂stergeler
    positive_indicators = [
        '√ßok iyi', 'harika', 'm√ºkemmel', 's√ºper', 'g√ºzel', 'beƒüendim',
        'memnun', 'te≈üekk√ºr', 'ba≈üarƒ±lƒ±', 'kaliteli', 'profesyonel',
        'sorunsuz', 'tam istediƒüimiz gibi', '√ßok g√ºzel', '√ßok ba≈üarƒ±lƒ±'
    ]
    
    neutral_count = sum(1 for indicator in neutral_indicators if indicator in text_lower)
    complaint_count = sum(1 for indicator in complaint_indicators if indicator in text_lower)
    positive_count = sum(1 for indicator in positive_indicators if indicator in text_lower)
    
    # N√∂tr yorum kriterleri - daha esnek:
    # 1. N√∂tr g√∂stergeler yeterli (2+)
    # 2. ≈ûikayet g√∂stergeleri az (2'den az)
    # 3. Pozitif g√∂stergeler varsa da n√∂tr olabilir (talep + pozitif = n√∂tr)
    if neutral_count >= 2 and complaint_count <= 1:
        return True
    
    # √ñzel durum: "her≈üey √ßok iyi sorunsuz fakat" gibi yapƒ±lar
    if 'fakat' in text_lower or 'ama' in text_lower or 'ancak' in text_lower:
        if neutral_count >= 1:
            return True
    
    # √ñzel durum: "istiyoruz", "talep ediyoruz" gibi direkt talepler
    if any(word in text_lower for word in ['istiyoruz', 'talep ediyoruz', 'rica ediyoruz']):
        if complaint_count == 0:
            return True
    
    # √ñzel durum: Personel, lojman, yemekhane gibi i≈ü yeri konularƒ±
    workplace_topics = ['personel', 'lojman', 'yemekhane', 'mescit', 'dinlenme', '√ßalƒ±≈üma']
    if any(topic in text_lower for topic in workplace_topics):
        if neutral_count >= 1 and complaint_count <= 1:
            return True
    
    return False

def clean_text(text: str) -> str:
    """Metni normalize et ve temizle"""
    text = text.lower()
    # T√ºrk√ße karakterleri koru, gereksiz i≈üaretleri temizle
    text = re.sub(r'[^\w\s√ßƒüƒ±√∂≈ü√º]', '', text)
    # Tekrar eden harfleri azalt (√∂r: aaa -> aa)
    text = re.sub(r'(.)\1{2,}', r'\1\1', text)
    # Fazla bo≈üluklarƒ± temizle
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def analyze_with_model(text: str, model_id: str) -> Dict[str, Any]:
    """Belirli bir model ile analiz"""
    try:
        pipeline = pipelines.get(model_id)
        if not pipeline:
            return {"error": f"Model {model_id} bulunamadƒ±"}
        
        result = pipeline(text)[0]
        label = str(result['label'])
        confidence = float(result['score'])
        
        # Model'e g√∂re etiket e≈üleme
        mapping = MAPPINGS.get(model_id, {})
        sentiment = mapping.get(label, label)
        
        return {
            "model_id": model_id,
            "sentiment": sentiment,
            "confidence": confidence,
            "raw_label": label
        }
    except Exception as e:
        return {"error": str(e)}

def combine_model_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """√áoklu model sonu√ßlarƒ±nƒ± birle≈ütir"""
    valid_results = [r for r in results if "error" not in r]
    
    if not valid_results:
        return {"error": "Hi√ßbir model √ßalƒ±≈ümadƒ±"}
    
    if len(valid_results) == 1:
        return valid_results[0]
    
    # √áoklu model sonu√ßlarƒ±nƒ± analiz et
    sentiments = [r["sentiment"] for r in valid_results]
    confidences = [r["confidence"] for r in valid_results]
    
    # En y√ºksek g√ºven skoruna sahip sonucu al
    best_result = max(valid_results, key=lambda x: x["confidence"])
    
    # Sonu√ßlar tutarlƒ± mƒ± kontrol et
    unique_sentiments = set(sentiments)
    is_consistent = len(unique_sentiments) == 1
    
    return {
        "final_sentiment": best_result["sentiment"],
        "final_confidence": best_result["confidence"],
        "model_used": best_result["model_id"],
        "consistency": is_consistent,
        "all_results": valid_results,
        "method": "multi_model"
    }

def analyze_comment(comment: str) -> Dict[str, Any]:
    """Tek yorum analizi - geli≈ümi≈ü hibrit yakla≈üƒ±m"""
    if not comment or len(comment.strip()) < 2:
        raise HTTPException(status_code=400, detail="Yorum √ßok kƒ±sa veya bo≈ü")
    
    # 1. √ñnce kural tabanlƒ± kontrol
    if is_neutral_comment(comment):
        return {
            "yorum": comment,
            "analiz": "N√∂tr",
            "g√ºven": 0.95,
            "y√∂ntem": "kural_tabanlƒ±",
            "a√ßƒ±klama": "Talep, √∂neri veya rica i√ßeren yorum",
            "model_sonu√ßlarƒ±": None
        }
    
    cleaned = clean_text(comment)
    if len(cleaned.split()) < 2:
        return {
            "yorum": comment,
            "analiz": "Ge√ßersiz / Yetersiz Yorum",
            "g√ºven": 0.0,
            "y√∂ntem": "kural_tabanlƒ±",
            "model_sonu√ßlarƒ±": None
        }
    
    try:
        # 2. √áoklu model analizi
        model_results = []
        for model_id in pipelines.keys():
            result = analyze_with_model(cleaned, model_id)
            if "error" not in result:
                model_results.append(result)
        
        # 3. Model sonu√ßlarƒ±nƒ± birle≈ütir
        combined_result = combine_model_results(model_results)
        
        if "error" in combined_result:
            raise Exception(combined_result["error"])
        
        final_sentiment = combined_result["final_sentiment"]
        final_confidence = combined_result["final_confidence"]
        
        # 4. Model sonucunu kontrol et - eƒüer √ßok y√ºksek g√ºvenle yanlƒ±≈ü sƒ±nƒ±flandƒ±rƒ±yorsa
        if final_confidence > 0.9 and final_sentiment == "Olumsuz":
            if is_neutral_comment(comment):
                return {
                    "yorum": comment,
                    "analiz": "N√∂tr",
                    "g√ºven": 0.90,
                    "y√∂ntem": "hibrit_d√ºzeltme",
                    "a√ßƒ±klama": "Model yanlƒ±≈ü sƒ±nƒ±flandƒ±rdƒ±, kural tabanlƒ± d√ºzeltme uygulandƒ±",
                    "model_sonu√ßlarƒ±": combined_result
                }
        
        return {
            "yorum": comment,
            "analiz": final_sentiment,
            "g√ºven": round(final_confidence, 3),
            "y√∂ntem": combined_result["method"],
            "model_sonu√ßlarƒ±": combined_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analiz hatasƒ±: {str(e)}")

def analyze_comments(comments: List[str]) -> List[Dict[str, Any]]:
    """Toplu yorum analizi"""
    if not comments:
        return []
    
    # Bo≈ü yorumlarƒ± filtrele
    valid_comments = [c.strip() for c in comments if c.strip()]
    if not valid_comments:
        return []
    
    try:
        outputs = []
        for comment in valid_comments:
            outputs.append(analyze_comment(comment))
        return outputs
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Toplu analiz hatasƒ±: {str(e)}")

def parse_csv_file(file_content: bytes) -> List[str]:
    """CSV dosyasƒ±ndan yorumlarƒ± oku"""
    try:
        content = file_content.decode('utf-8')
        csv_reader = csv.reader(io.StringIO(content))
        comments = []
        for row in csv_reader:
            if row and row[0].strip():
                comments.append(row[0].strip())
        return comments
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"CSV okuma hatasƒ±: {str(e)}")

def parse_txt_file(file_content: bytes) -> List[str]:
    """TXT dosyasƒ±ndan yorumlarƒ± oku"""
    try:
        content = file_content.decode('utf-8')
        lines = [line.strip() for line in content.splitlines() if line.strip()]
        return lines
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"TXT okuma hatasƒ±: {str(e)}")

@app.get("/", response_class=HTMLResponse)
async def read_root():
    """Ana sayfa - HTML aray√ºz√ºn√º serve et"""
    try:
        html_path = os.path.join("static", "index.html")
        if os.path.exists(html_path):
            with open(html_path, "r", encoding="utf-8") as f:
                return HTMLResponse(content=f.read())
        else:
            # HTML dosyasƒ± bulunamadƒ±ysa basit bir sayfa d√∂nd√ºr
            return HTMLResponse(content="""
            <!DOCTYPE html>
            <html lang="tr">
            <head>
                <meta charset="UTF-8">
                <title>T√ºrk√ße Duygu Analizi - √áoklu Model</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 40px; }
                    .container { max-width: 800px; margin: 0 auto; }
                    .endpoint { background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 5px; }
                    .method { font-weight: bold; color: #007bff; }
                    .model-info { background: #e8f4fd; padding: 15px; margin: 10px 0; border-radius: 5px; }
                </style>
            </head>
            <body>
                <div class="container">
                    <h1>üé≠ T√ºrk√ße Duygu Analizi API - √áoklu Model</h1>
                    <p>API √ßalƒ±≈üƒ±yor! Kullanƒ±labilir endpoint'ler:</p>
                    
                    <div class="model-info">
                        <h3>ü§ñ Y√ºkl√º Modeller</h3>
                        <ul>
                            <li><strong>savasy</strong>: T√ºrk√ße sentiment i√ßin √∂zel eƒüitilmi≈ü</li>
                            <li><strong>dbmdz</strong>: Genel T√ºrk√ße BERT modeli</li>
                        </ul>
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">GET</span> <code>/</code> - Bu sayfa
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">POST</span> <code>/analyze</code> - Tek yorum analizi
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">POST</span> <code>/analyze-batch</code> - Toplu yorum analizi (JSON)
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">POST</span> <code>/upload</code> - Dosya y√ºkleme ve analiz
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">GET</span> <code>/health</code> - Saƒülƒ±k kontrol√º
                    </div>
                    
                    <div class="endpoint">
                        <span class="method">GET</span> <code>/docs</code> - Swagger dok√ºmantasyonu
                    </div>
                    
                    <h3>üìù √ñrnek Kullanƒ±m</h3>
                    <p><strong>Tek yorum analizi:</strong></p>
                    <pre>curl -X POST "http://localhost:8000/analyze" \
     -H "Content-Type: application/json" \
     -d '{"text": "Bu √ºr√ºn harika!"}'</pre>
                    
                    <p><strong>Dosya y√ºkleme:</strong></p>
                    <pre>curl -X POST "http://localhost:8000/upload" \
     -F "file=@ornek_yorumlar.txt"</pre>
                </div>
            </body>
            </html>
            """)
    except Exception as e:
        return HTMLResponse(content=f"""
        <html>
            <head><title>Hata</title></head>
            <body><h1>Hata olu≈ütu: {str(e)}</h1></body>
        </html>
        """)

@app.post("/analyze")
async def analyze_single(comment: Comment):
    """Tek yorum analizi"""
    return analyze_comment(comment.text)

@app.post("/analyze-batch")
async def analyze_batch(payload: Comments):
    """JSON ile toplu yorum analizi"""
    return analyze_comments(payload.texts)

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """Dosya y√ºkleme ve analiz"""
    if not file.filename:
        raise HTTPException(status_code=400, detail="Dosya adƒ± bulunamadƒ±")
    
    # Dosya boyutu kontrol√º (5MB)
    if file.size and file.size > 5 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="Dosya √ßok b√ºy√ºk (max 5MB)")
    
    try:
        content = await file.read()
        
        if file.filename.lower().endswith('.csv'):
            comments = parse_csv_file(content)
        elif file.filename.lower().endswith('.txt'):
            comments = parse_txt_file(content)
        else:
            raise HTTPException(status_code=400, detail="Sadece .csv ve .txt dosyalarƒ± desteklenir")
        
        if not comments:
            raise HTTPException(status_code=400, detail="Dosyada ge√ßerli yorum bulunamadƒ±")
        
        results = analyze_comments(comments)
        return {
            "dosya_adi": file.filename,
            "yorum_sayisi": len(comments),
            "sonuclar": results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Dosya i≈üleme hatasƒ±: {str(e)}")

@app.get("/health")
async def health_check():
    """Saƒülƒ±k kontrol√º"""
    return {
        "status": "healthy", 
        "models": {model_id: {"name": info["name"], "status": "loaded"} for model_id, info in MODELS.items()},
        "pipelines": list(pipelines.keys())
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
